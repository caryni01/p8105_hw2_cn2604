---
title: "p8105_hw2_cn2604"
output: github_document
date: "2022-09-27"
---

```{r load_library,echo = FALSE, message=FALSE}
library(tidyverse)
library(readxl)
```
# Problem 1
```{r clean_file_1, echo=FALSE, message=FALSE}
transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    entry = recode(entry, 'YES' = 'TRUE', 'NO' = 'FLASE'),
    entry = as.logical(entry),
    corner = as.factor(corner),
    staffing = as.factor(staffing),
    entrance_type = as.factor(entrance_type),
    division = as.factor(division),
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  ) %>% 
  unite(col = 'unique_station_name', c('station_name', 'line'), sep = ' ')
  
  
```
The primary variables of this dataset are the name and location of the stations, their divisions and lines with different routes, the types of entrance and their locations. Other additional information such as presence of staffs, vending, ADA, and crossing over are also provided.
My __cleaning steps__ are 
1) Read the csv documents and clean the names with janitor.
2) Convert _entry_ variable to logical variable, _corner_, _staffing_, _entrance_type_, and _division_ to factor variables, and convert _route8_ to _route11_ to character variables.
3) To make tidy data by separating the variables of _route_name_ and _route_number_ with pivot_longer function.
4) Combine the column of _station_name_ and _line_ to _unique_station_name_ as a mark the station.

This processed dataset has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns. Since the variables of  _route_name_ and _route_number_ are manipulated to make each column a variable and each row an observation, data in this set are now tidy. 

```{r count_stations, echo=FALSE, message=FALSE}
station_number = n_distinct(transit_df$unique_station_name)
station_ada = n_distinct(transit_df$unique_station_name[transit_df$ada == TRUE])
total_no_vending = n_distinct(transit_df$unique_station_name[transit_df$vending == 'NO'])

no_vending_with_entrance = n_distinct(transit_df$unique_station_name[transit_df$vending == 'NO' & transit_df$entry == TRUE])

station_proportion = round(no_vending_with_entrance/total_no_vending, digits = 2)

route_a_station = n_distinct(transit_df$unique_station_name[transit_df$route_name == 'A'])

route_a_station_ada = n_distinct(transit_df$unique_station_name[transit_df$route_name == 'A' & transit_df$ada == TRUE])
```

There are `r station_number` unique stations and `r station_ada` of them are ADA compliant. `r station_proportion` of the stations without vending allow entrance.

`r route_a_station` distinct stations serve A train and `r route_a_station_ada` of them are ADA compliant.

# Problem 2

```{r clean_file_2, echo=FALSE, message=FALSE}
mr_trash_df = read_excel("./data/Trash Wheel Collection Data.xlsx",
                      sheet = 'Mr. Trash Wheel',
                      range = "A2:N550") %>% 
  janitor::clean_names() %>% 
  na.omit() %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  ) %>% 
  add_column(type = "Mr.Trash Wheel", .after = "dumpster")

pro_trash_df = read_excel("./data/Trash Wheel Collection Data.xlsx",
                      sheet = 'Professor Trash Wheel',
                      range = "A2:M97") %>% 
  janitor::clean_names() %>% 
  na.omit() %>% 
  add_column(type = "Professor Trash Wheel", .after = "dumpster") %>% 
  add_column(sports_balls = 0, .after= "chip_bags")

combined_trash_df = rbind(mr_trash_df, pro_trash_df) %>% 
  mutate(dumpster = as.integer(dumpster)) %>% 
  arrange(dumpster)

pro_trash_weight = sum(combined_trash_df$weight_tons[combined_trash_df$type == "Professor Trash Wheel"])
mr_trash_ball = sum(combined_trash_df$sports_balls[combined_trash_df$type == "Mr.Trash Wheel" & combined_trash_df$year == 2020])
```
There are `r nrow(combined_trash_df)` observations and `r ncol(combined_trash_df)` variables. The keys variables are the datetime for each dumpsters and different categories of trash including plastic bottles, polystyrene, cigarette butts, and sports balls etc. The volume occupied and total weight for each dumpster are also recorded. 

The total trash weight collected by Professor Trash Wheel is `r pro_trash_weight` tons. The total number of sports balls collected by Mr.Trash Wheel in 2020 is `r mr_trash_ball`.

# Problem 3

```{r clean_file_3, echo=FALSE, message=FALSE}
pols_df = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day"), sep = '-') %>% 
  mutate(
    month = as.numeric(month),
    year = as.numeric(year),
    month = tolower(month.abb[month]),
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) %>% 
  relocate(president, .after = month) %>% 
  select(-c(prez_gop, prez_dem, day))
  
snp_df = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  mutate(
    month = as.numeric(month),
    month = tolower(month.abb[month]),
    year = as.numeric(year),
    year = ifelse(year >= 50, year + 1900, year +2000)
  ) %>% 
  relocate(month, .after = year) %>% 
  select(-day)

unemp_df = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
  )

combined_pol_df = merge(pols_df, snp_df, by = c("year", "month") )
combined_all_df = merge(combined_pol_df, unemp_df, by = c("year", "month"))
```
The dataset of __pols-month__ has `r nrow(pols_df)` observations and `r ncol(pols_df)` variables after cleaning process. The year range is between `r min(pols_df$year)` and `r max(pols_df$year)`. The important variables are `r names(select(pols_df, -c(year, month)))`, which specifies the political party of the president, number of governors, senators, and representatives at that time.

The dataset of __snp__ has `r nrow(snp_df)` observations and `r ncol(snp_df)` variables after cleaning process. The year range is between `r min(snp_df$year)` and `r max(snp_df$year)`. The important variable is `r names(select(snp_df, -c(year, month)))`, which shows the closing values of the S&P stock index at that time.

The dataset of __unempolyment__ has `r nrow(unemp_df)` observations and `r ncol(unemp_df)` variables after cleaning process. The year range is between `r min(unemp_df$year)` and `r max(unemp_df$year)`. The important variable is `r names(select(unemp_df, -c(year, month)))`, which shows the unemployment rate at that time.

The __final combined__ dataset of has `r nrow(combined_all_df)` observations and `r ncol(combined_all_df)` variables after cleaning process. The year range is between `r min(combined_all_df$year)` and `r max(combined_all_df$year)`. The important variable is `r names(select(combined_all_df, -c(year, month)))`, which contains all of the informations from the datasets above and the time.

